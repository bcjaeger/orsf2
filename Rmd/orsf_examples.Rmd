
# Examples

`orsf()` is the entry-point of the `aorsf` package. It can be used to fit classification, regression, and survival forests. It can also compute out-of-bag prediction accuracy or out-of-bag variable importance using built-in functions or custom functions supplied by users.  

```{r, echo=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

First we load some relevant packages

```{r, message=FALSE, warning=FALSE}

set.seed(329730)
library(aorsf)
library(tidyverse)
library(survival)

```


## Classification

We'll use the outstanding `penguin` data for this example:

```{r}

# penguins_orsf is a copy of the penguins data
# from palmerpenguins but only includes complete cases:
head(penguins_orsf)

```

The `orsf()` function will automatically fit a classification forest if the outcome variable is a factor:

```{r}

fit_penguins <- orsf(data = penguins_orsf,
                     formula = species ~ bill_length_mm + flipper_length_mm)

fit_penguins

```

You can also tell `orsf()` to do classification manually if you'd prefer keeping a numeric outcome. The way to do this is through the `control` argument:

```{r}

penguins_numeric <- penguins_orsf
penguins_numeric$species <- as.numeric(penguins_numeric$species)

fit_numeric <- orsf(penguins_numeric,
                    formula = species ~ bill_length_mm + flipper_length_mm,
                    control = orsf_control_classification())

fit_numeric

```

You could also use `orsf_update` to make `fit_numeric` simply by giving it a new `data` argument

```{r}

orsf_update(fit_penguins, data = penguins_numeric)

```

### Difference between oblique and axis-based

For this example, we modify integer columns in the penguins data to be doubles so that `aorsf` will not throw an error when we ask it to predict at non-integer values of these predictors:

```{r}

penguins_orsf <- penguins_orsf %>% 
 mutate(bill_length_mm = as.numeric(bill_length_mm),
        flipper_length_mm = as.numeric(flipper_length_mm))

```

We will also use the same code to make several plots, so I define a function below to minimize repetition.

```{r}

plot_decision_surface <- function(predictions, grid, title){
 
 # this is not a general function for plotting
 # decision surfaces. It just helps to minimize 
 # copying and pasting of code.
 
 colnames(predictions) <- levels(penguins_orsf$species)
 
 class_preds <- bind_cols(grid, predictions) %>%
  pivot_longer(cols = c(Adelie,
                        Chinstrap,
                        Gentoo)) %>%
  group_by(flipper_length_mm, bill_length_mm) %>%
  arrange(desc(value)) %>%
  slice(1)
 
 cols <- c("darkorange", "purple", "cyan4")

 ggplot(class_preds, aes(bill_length_mm, flipper_length_mm)) +
  geom_contour_filled(aes(z = value, fill = name),
                      alpha = .25) +
  geom_point(data = penguins_orsf,
             aes(color = species, shape = species),
             size = 3,
             alpha = 0.8) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = cols) +
  labs(x = "\nBill length, scaled",
       y = "Bill depth, scaled\n") +
  theme_minimal() +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  theme(panel.grid = element_blank(),
        panel.border = element_rect(fill = NA),
        legend.position = '') + 
  labs(title = title)
 
}

```

We also use a grid of points for plotting the decision surface, which is created as follows:

```{r}

grid <- expand_grid(

 flipper_length_mm = seq(min(penguins_orsf$flipper_length_mm),
                     max(penguins_orsf$flipper_length_mm),
                  len = 200),
 bill_length_mm = seq(min(penguins_orsf$bill_length_mm),
                      max(penguins_orsf$bill_length_mm),
                      len = 200)
)

```


Axis-based random forests comprise axis-based trees, which partition data by splitting them into subgroups using a single variable. 

```{r}

# ranger and randomForestSRC are fantastic packages for
# axis-based random forests. For simplicity, we use orsf
# to fit one here. Note that orsf with mtry = 1 is similar
# to an extremely randomized axis-based forest 

fit_axis_tree <- penguins_orsf %>% 
 orsf(species ~ bill_length_mm + flipper_length_mm,
      n_tree = 1,
      mtry = 1,
      tree_seeds = 106760)

pred_axis_tree <- predict(fit_axis_tree, new_data = grid)

```

With axis-based splits, decision boundaries will always be perpendicular to the axis of the relevant predictor:

```{r}

plot_decision_surface(pred_axis_tree, grid, "Axis-based tree")

```

When predictions from hundreds of axis-based trees are aggregated, the collective decision surface is much more flexible. However, even with hundreds of axis-based trees, it is difficult to capture smooth decision boundaries:

```{r}

fit_axis_forest <- fit_axis_tree %>% 
 orsf_update(n_tree = 500)

pred_axis_forest <- predict(fit_axis_forest, new_data = grid)

plot_decision_surface(pred_axis_forest, grid, "Axis-based forest")

```


Instead of using a single predictor to split data, oblique trees use a weighted combination of predictors. This creates decision boundaries that are neither parallel or perpendicular to the axes of corresponding predictors:

```{r}

fit_oblique_tree <- fit_axis_tree %>% 
 orsf_update(mtry = 2)

pred_oblique_tree <- predict(fit_oblique_tree, new_data = grid)

plot_decision_surface(pred_oblique_tree, grid, "Oblique tree")

```

And, when predictions from these trees are aggregated, they do a great job of capturing smooth geometries!

```{r}

fit_oblique_forest <- fit_oblique_tree %>% 
 orsf_update(n_tree = 500)

pred_oblique_forest <- predict(fit_oblique_forest, 
                               new_data = grid)

plot_decision_surface(pred_oblique_forest, grid, "Oblique forest")

```


## Regression



## Survival

```{r}

fit <- orsf(pbc_orsf, Surv(time, status) ~ . - id)

```

printing `fit` provides quick descriptive summaries:

```{r}
fit
```


## More than one way to grow a forest

You can use `orsf(no_fit = TRUE)` to make a specification to grow a forest that can be used as a blueprint for `orsf_train()`:

```{r}

orsf_spec <- orsf(pbc_orsf, time + status ~ . - id, no_fit = TRUE)
orsf_spec

```


```{r}

orsf_fit <- orsf_train(orsf_spec)
orsf_fit

```

You can also update the specification in place when passing it to `orsf_train()`, making it easy to fit several models from one spec:

```{r}

orsf_fit_10 <- orsf_train(orsf_spec, leaf_min_obs = 10)
orsf_fit_20 <- orsf_train(orsf_spec, leaf_min_obs = 20)

orsf_fit$leaf_min_obs
orsf_fit_10$leaf_min_obs
orsf_fit_20$leaf_min_obs

```

## tidymodels

`tidymodels` includes support for `aorsf` as a computational engine:

```{r, warning=FALSE, echo=TRUE, message=FALSE}

library(tidymodels)
library(censored)
library(yardstick)

pbc_tidy <- pbc_orsf %>% 
 mutate(event_time = Surv(time, status), .before = 1) %>% 
 select(-c(id, time, status)) %>% 
 as_tibble()

split  <- initial_split(pbc_tidy)

orsf_spec <- rand_forest() %>% 
 set_engine("aorsf") %>% 
 set_mode("censored regression")

orsf_fit <- fit(orsf_spec, event_time ~ ., data = training(split))

```

Prediction with `aorsf` models at different times is also supported:

```{r}

time_points <- seq(500, 3000, by = 500)

test_pred <- augment(orsf_fit, 
                     new_data = testing(split), 
                     eval_time = time_points)

brier_scores <- test_pred %>% 
  brier_survival(truth = event_time, .pred)

brier_scores

roc_scores <- test_pred %>% 
  roc_auc_survival(truth = event_time, .pred)

roc_scores

```



---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

#' @srrstats {G1.2} *Project status describes current and anticipated future states of development.* 
 
```

# aorsf <a href="https://bcjaeger.github.io/aorsf/"><img src="man/figures/logo.png" align="right" height="138" /></a>




<!-- badges: start -->
[![Project Status: Active â€“ The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
  [![Codecov test coverage](https://codecov.io/gh/bcjaeger/aorsf/branch/master/graph/badge.svg)](https://app.codecov.io/gh/bcjaeger/aorsf?branch=master)
[![R-CMD-check](https://github.com/bcjaeger/aorsf/workflows/R-CMD-check/badge.svg)](https://github.com/bcjaeger/aorsf/actions/)
[![Status at rOpenSci Software Peer Review](https://badges.ropensci.org/532_status.svg)](https://github.com/ropensci/software-review/issues/532/)
<a href="https://joss.theoj.org/papers/414871f081cd8449007d671a7f7f7c3a"><img src="https://joss.theoj.org/papers/414871f081cd8449007d671a7f7f7c3a/status.svg"></a>
[![CRAN status](https://www.r-pkg.org/badges/version/aorsf)](https://CRAN.R-project.org/package=aorsf)
<!-- badges: end -->

Fit, interpret, and make predictions with oblique random survival forests (ORSFs).  


## Why aorsf?

- Hundreds of times faster than `obliqueRSF`.^1^

- Accurate predictions for censored outcomes.^2^

- Negation importance, a novel technique to estimate variable importance for ORSFs.^2^

- Intuitive API with formula based interface.

- Extensive input checks and informative error messages.

## Installation

You can install the development version of aorsf from [GitHub](https://github.com/) with:

``` r
# install.packages("remotes")
remotes::install_github("bcjaeger/aorsf")
```

## What is an oblique decision tree?

Decision trees are developed by splitting a set of training data into two new subsets, with the goal of having more similarity within the new subsets than between them. The splitting process is repeated on resulting subsets of data until a stopping criterion is met. 

When the new subsets of data are formed based on a single predictor, the decision tree is said to be *axis-based* because the splits of the data appear perpendicular to the axis of the predictor. When linear combinations of variables are used instead of a single variable, the tree is *oblique* because the splits of the data are neither parallel nor at a right angle to the axis. 

**Figure**: Decision trees for classification with axis-based splitting (left) and oblique splitting (right). Cases are orange squares; controls are purple circles. Both trees partition the predictor space defined by variables X1 and X2, but the oblique splits do a better job of separating the two classes.


```{r fig_oblique_v_axis, out.width='100%', echo = FALSE}

knitr::include_graphics('man/figures/tree_axis_v_oblique.png')

```

## Examples

The `orsf()` function can fit several types of ORSF ensembles. My personal favorite is the accelerated ORSF because it has a great combination of prediction accuracy and computational efficiency (see [arXiv paper](https://arxiv.org/abs/2208.01129)).^2^

```{r, child='Rmd/orsf-fit-accelerated.Rmd'}

```

### Inspect

Printing the output from `orsf()` will give some information and descriptive statistics about the ensemble.

```{r}

fit

```

- See [print.orsf_fit](https://bcjaeger.github.io/aorsf/reference/print.orsf_fit.html) for a description of each line in the printed output.

- See [orsf examples](https://bcjaeger.github.io/aorsf/reference/orsf.html#examples) for more details on controlling ORSF ensemble fits and using them in prediction modeling workflows.

### Variable importance

The importance of individual variables can be estimated in three ways using `aorsf`:

- **negation**^2^: `r aorsf:::roxy_vi_describe('negate')`

  ```{r}
  
  orsf_vi_negate(fit)
  
  ```

- **permutation**: `r aorsf:::roxy_vi_describe('permute')`

  ```{r}
  
  orsf_vi_permute(fit)
  
  ```
  
- **analysis of variance (ANOVA)**^3^: `r aorsf:::roxy_vi_describe('anova')`

  ```{r}
  
  orsf_vi_anova(fit)
  
  ```

You can supply your own R function to estimate out-of-bag error when using negation or permutation importance. This feature is experimental and may be changed in the future (see [oob vignette](https://bcjaeger.github.io/aorsf/articles/oobag.html))

### Partial dependence (PD) 

`r aorsf:::roxy_pd_explain()`

For more on PD, see the [vignette](https://bcjaeger.github.io/aorsf/articles/pd.html)

### Individual conditional expectations (ICE)

`r aorsf:::roxy_ice_explain()`


For more on ICE, see the [vignette](https://bcjaeger.github.io/aorsf/articles/pd.html#individual-conditional-expectations-ice)

## Comparison to existing software

Comparisons between `aorsf` and existing software are presented in our [arXiv paper](https://arxiv.org/abs/2208.01129). The paper

- describes `aorsf` in detail with a summary of the procedures used in the tree fitting algorithm 

- runs a general benchmark comparing `aorsf` with `obliqueRSF` and several other learners 

- reports prediction accuracy and computational efficiency of all learners.

- runs a simulation study comparing variable importance techniques with ORSFs, axis based RSFs, and boosted trees.

- reports the probability that each variable importance technique will rank a relevant variable with higher importance than an irrelevant variable.

A more hands-on comparison of `aorsf` and other R packages is provided in [orsf examples](https://bcjaeger.github.io/aorsf/reference/orsf.html#tidymodels)


## References

```{r results='asis', echo=FALSE}

cat("1. ", aorsf:::roxy_cite_jaeger_2019(), '\n\n')

cat("2. ", aorsf:::roxy_cite_jaeger_2022(), '\n\n')

cat("3. ", aorsf:::roxy_cite_menze_2011())

```


## Funding

The developers of `aorsf` receive financial support from the Center for Biomedical Informatics, Wake Forest University School of Medicine. We also receive support from the National Center for Advancing Translational Sciences of the National Institutes of Health under Award Number UL1TR001420. 

The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.

